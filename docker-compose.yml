
version: "3.7"
services:

#service : definition of Zookeeper

  zookeeper1:
    image: confluentinc/cp-zookeeper:6.1.0
    hostname: zookeeper1
    container_name: zookeeper1
    ports:
      - "22181:22181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 22181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 20
      ZOOKEEPER_SYNC_LIMIT: 10
      ZOOKEEPER_SERVERS: zookeeper1:22888:23888;zookeeper2:32888:33888


  zookeeper2:
    image: confluentinc/cp-zookeeper:6.1.0
    hostname: zookeeper2
    container_name: zookeeper2
    ports:
      - "32181:32181"
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 32181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 20
      ZOOKEEPER_SYNC_LIMIT: 10
      ZOOKEEPER_SERVERS: zookeeper1:22888:23888;zookeeper2:32888:33888


#service : definition of kafka

  kafka1:
    image: confluentinc/cp-server:6.1.0
    hostname: kafka1
    container_name: kafka1
    depends_on:
      - zookeeper1
      - zookeeper2
    ports:
      - "19092:19092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper1:22181,zookeeper2:32181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:19092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka1:19092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 2
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_BALANCER_ENABLE: 'true'
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
    restart: on-failure

  kafka2:
    image: confluentinc/cp-server:6.1.0
    hostname: kafka2
    container_name: kafka2
    depends_on:
      - zookeeper1
      - zookeeper2
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper1:22181,zookeeper2:32181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka2:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 2
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_BALANCER_ENABLE: 'true'
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
    restart: on-failure  

  kafka3:
    image: confluentinc/cp-server:6.1.0
    hostname: kafka3
    container_name: kafka3
    depends_on:
      - zookeeper1
      - zookeeper2
    ports:
      - "39092:39092"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT:  'zookeeper1:22181,zookeeper2:32181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092,PLAINTEXT_HOST://localhost:39092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka3:39092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 2
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_BALANCER_ENABLE: 'true'
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
    restart: on-failure  

#service : definition of schema-registry

  schema-registry:
    image: confluentinc/cp-schema-registry:6.1.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - zookeeper1
      - zookeeper2
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka1:9092,kafka2:9092,kafka3:9092'
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL:  'zookeeper1:22181,zookeeper2:32181'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,DELETE,OPTIONS,HEAD'
    restart: on-failure


#service : creation of kafka topic

  kafka-setup:
    image: confluentinc/cp-enterprise-kafka:6.1.0
    hostname: kafka-setup
    container_name: my-kafka-setup
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - zookeeper1
      - zookeeper2
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -z 'zookeeper1:22181,zookeeper2:32181'  1 30 && \
                       kafka-topics --create --if-not-exists --zookeeper 'zookeeper1:22181,Zookeeper2:32181'   --partitions 3 --replication-factor 2 --topic tenderTopic && \
                       kafka-topics --create --if-not-exists --zookeeper 'zookeeper1:22181,zookeeper2:32181'   --partitions 1 --replication-factor 1 --topic randomData && \
                       kafka-topics --create --if-not-exists --zookeeper 'zookeeper1:22181,zookeeper2:32181'   --partitions 1 --replication-factor 1 --topic KTable'"
    environment:
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
    restart: on-failure


#service : definition of mysql database

  db:
    image: mysql
    container_name: mysql-db
    build:
        context: .
        dockerfile: Dockerfile.db
    environment:
        - MYSQL_ROOT_PASSWORD=root
        - MYSQL_DATABASE:xmlstore
    volumes:
        - db_data:/var/lib/mysql
    ports:
        - "3306:3306"
    restart: always

#service : definition of phpMyAdmin
  phpmyadmin:
    image: phpmyadmin/phpmyadmin:latest
    container_name: my-php-myadmin
    ports:
        - "8084:80"
    restart: always
    depends_on:
        - db
    environment:
        SPRING_DATASOURCE_USERNAME: root
        SPRING_DATASOURCE_PASSWORD: root


#service : definition of your Spring API for Consumer2
  bootservice:                        
    image: boot-app               
    container_name: boot-service-app  
    build:
        context: .                          
        dockerfile: Dockerfile.xmlapi           
    ports:
        - "8080:8080"                       
    restart: always
    depends_on:                      
        - db                               
    environment:
        SPRING_DATASOURCE_URL: jdbc:mysql://mysql-db:3306/xmlstore
        SPRING_DATASOURCE_USERNAME: root
        SPRING_DATASOURCE_PASSWORD: root
        SPRING_JPA_PROPERTIES_HIBERNATE_ID_NEW_GENERATOR_MAPPINGS: 'false'
 

#service : definition of your StreamAPI
  kafka-producer:
    image: kafka-producer
    container_name: kafka-producer
    hostname: kafka-producer
    build:
        context: .
        dockerfile: Dockerfile.kafkaproducer
    restart: on-failure



#service : definition of your SoapAPI
  soapservice:                        
    image: soap-app               
    container_name: soap-service-app  
    hostname: soapservice
    build:
        context: .                          
        dockerfile: Dockerfile.soap              
    ports:
        - "9090:9090"
   

#service : definition of your SpringBootKafkaStreamss - converts JSON to SOAPXML
  soapxml:
    image: soap-xml
    container_name: soap-xml
    hostname: soapxml
    build:
        context: .
        dockerfile: Dockerfile.wsdl
    restart: on-failure

#service : definition of your Kafka-consumer
  kafkaconsumer:
    image: kafka-consumer
    container_name: kafka-consumer
    hostname: kafka-consumer
    build:
        context: .
        dockerfile: Dockerfile.kafkaconsumer
    restart: on-failure



#service : definition of kafka connect

  connect:
    image: connect
    hostname: connect
    container_name: connect
    build:
        context: .                          
        dockerfile: Dockerfile.connect    
    depends_on:
      - zookeeper1
      - zookeeper2
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka1:9092,kafka2:9092,kafka3:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 2
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper1:22181,zookeeper2:32181'
      CONNECT_PLUGIN_PATH: '/usr/share/java,/etc/kafka-connect/jars'
      CONNECT_ACCESS_CONROL_ALLOW_ORIGIN: '*'
      CONNECT_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,DELETE,OPTIONS,ALWAYS,HEAD'
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-6.1.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
    restart: always
    volumes:
      - ./kafka-connect:/etc/kafka-connect/jars


#service : definition of conrol-centre

  control-center:
    image: confluentinc/cp-enterprise-control-center:6.1.0
    hostname: control-center
    container_name: control-center
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
      - connect
      - ksqldb-server
    ports:
      - "7072:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka1:9092,kafka2:9092,kafka3:9092'
      CONTROL_CENTER_CONNECT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_CONTROL_CENTER_DEPRECATED_VIEWS_ENABLE: 'true'    
     # CONFLUENT_CONTROL_CENTER_SERVICE_HEALTHCHECK_INTERVAL_SEC: 30
      CONFLUENT_CONTROL_CENTER_TOPIC_INSPECTION_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_BROKER_CONFIG_EDIT_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_LICENSE_MANAGER_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_CONSUMERS_VIEW_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_KSQL_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_SCHEMA_REGISTRY_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_USAGE_DATA_COLLECTION_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_UI_REPLICATOR_MONITORING_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_UI_CONTROLLER_CHART_ENABLE: 'true'
      CONFLUENT_CONTROL_CENTER_WEBHOOK_ENABLED: 'true'
      CONTROL_CENTER_STREAMS_CPREST_URL: "http://kafka1:9092,http://kafka2:9092,http://kafka3:9092"
      PORT: 9021

#service : definition of rest-proxy


  rest-proxy:
    image: confluentinc/cp-kafka-rest:6.1.0
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
    ports:
      - 8082:8082
    hostname: rest-proxy
    container_name: rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'kafka1:9092,kafka2:9092,kafka3:9092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      KAFKA_REST_CLIENT_ACCESS_CONROL_ALLOW_ORIGIN: '*'
      KAFKA_REST_CLIENT_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,DELETE,OPTIONS,HEAD'
      KAFKA_REST_CLIENT_ACCESS_CONTROL_ALLOW_HEADERS: 'origin,content-type,accept,authorization'

#service : definition of ksql-db server

  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:6.1.0
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - connect
    ports:
      - "8088:8088"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      KSQL_BOOTSTRAP_SERVERS: "kafka1:9092,kafka2:9092,kafka3:9092"
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: "http://ksqldb-server:8088"
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'

#service : definition of ksql-cli

  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:6.1.0
    container_name: ksqldb-cli
    depends_on:
      - kafka1
      - kafka2
      - kafka3
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true

#service : definition of ksql-datagen

  ksql-datagen:
    image: confluentinc/ksqldb-examples:6.1.0
    hostname: ksql-datagen
    container_name: ksql-datagen
    depends_on:
      - ksqldb-server
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
      - connect
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b 'kafka1:9092,kafka2:92,kafka3:9092' 1 40 && \
                       echo Waiting for Confluent Schema Registry to be ready... && \
                       cub sr-ready schema-registry 8081 40 && \
                       echo Waiting a few seconds for topic creation to finish... && \
                       sleep 11 && \
                       tail -f /dev/null'"
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql"
      STREAMS_BOOTSTRAP_SERVERS: 'kafka1:9092,kafka2:92,kafka3:9092'
      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
      STREAMS_SCHEMA_REGISTRY_PORT: 8081



volumes:
   db_data:


